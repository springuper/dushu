# 数据提取与发布操作手册

> **完整操作指南**：本文档提供从数据准备到发布的完整操作流程，适合日常使用。  
> **技术规范**：详细技术规范请参考 [数据获取与融合规格书](../specs/data-acquisition-and-merge-spec.md)

---

## 📋 目录

1. [前置要求](#前置要求)
2. [快速开始](#快速开始)
3. [完整流程](#完整流程)
4. [详细步骤](#详细步骤)
5. [推荐章节](#推荐章节)
6. [常见问题](#常见问题)
7. [最佳实践](#最佳实践)

---

## 前置要求

### 环境设置

1. **Node.js 环境**
   ```bash
   # 安装依赖
   npm install
   
   # 安装 Playwright 浏览器（用于下载脚本）
   npx playwright install chromium
   ```

2. **Python 环境**（用于 LLM 提取脚本，可选）
   ```bash
   # 创建虚拟环境
   python3 -m venv venv
   source venv/bin/activate
   
   # 安装依赖
   pip install -r scripts/requirements.txt
   ```
   
   **注意**：如果使用系统内的提取功能（推荐），可以跳过 Python 环境设置。

3. **API Key 配置**（用于系统内提取）
   ```bash
   # 使用设置脚本
   ./scripts/setup_env.sh
   
   # 或手动编辑 .env 文件
   # 设置 GOOGLE_API_KEY 或 OPENAI_API_KEY
   ```
   
   **推荐使用 Google Gemini**：
   - ✅ 免费额度更慷慨
   - ✅ 中文支持优秀
   - ✅ 速度快、成本低
   
   详细设置请参考：[Google Gemini API 设置](../scripts/GEMINI_SETUP.md)

### 服务启动

确保以下服务已启动：
- ✅ 数据库（`podman compose up -d`）
- ✅ 后端服务（`npm run dev:backend`）
- ✅ 前端服务（`npm run dev:frontend`）

---

## 🚀 快速开始

### 最简单的流程（3 步）

如果已有预处理好的章节 JSON 文件：

```
1. 上传章节 → 2. 提取数据 → 3. 批量审核
```

**预计时间**：10-15 分钟（取决于章节大小和审核数据量）

### 完整流程（包含数据准备）

如果还没有章节 JSON 文件：

```
1. 下载原始文本（脚本） → 2. 预处理（脚本） → 3. 上传章节 → 4. 提取数据 → 5. 批量审核
```

**预计时间**：15-20 分钟

---

## 📖 完整流程

### 流程图

```
获取原始文本
    ↓
预处理（生成 JSON）
    ↓
上传章节到系统
    ↓
在章节处理页面提取数据
    ↓
批量审核（通过即发布）
    ↓
完成 ✅
```

---

## 🔧 详细步骤

### 步骤 1：准备章节数据

> **提示**：如果已经有预处理好的 JSON 文件，可以跳过步骤 1.1 和 1.2，直接进入步骤 2。

#### 1.1 获取原始文本

**方法 1：使用脚本自动下载（推荐）**

使用 Playwright 脚本自动从维基文库下载：

```bash
# 使用便捷脚本（推荐，一键完成下载和预处理）
./scripts/download_first_chapter_auto.sh

# 或手动运行下载脚本
node scripts/download_with_playwright.js \
  --url "https://zh.wikisource.org/wiki/史記/卷008" \
  --output "data/raw/shiji/shiji_01_gaozu_benji.txt" \
  --book "史记" \
  --chapter "高祖本纪"
```

**参数说明**：
- `--url`: 维基文库页面 URL（必需）
- `--output`: 输出文件路径（必需）
- `--book`: 书籍名称（可选）
- `--chapter`: 章节名称（可选）

**前提条件**：
- 已安装 Node.js 依赖：`npm install`
- 已安装 Playwright 浏览器：`npx playwright install chromium`

**方法 2：手动下载**

如果自动下载失败，可以手动下载：

1. 访问维基文库：https://zh.wikisource.org
2. 搜索书籍（如"史记"）
3. 选择具体章节
4. 复制文本内容
5. 保存为 UTF-8 编码的文本文件

**文件格式要求**：
- 编码：UTF-8
- 格式：段落之间用空行分隔
- 位置：`data/raw/{book}/` 目录
- 命名：`{book}_{chapter}_{title}.txt`

**文件开头建议包含**：
```
来源：《史记·高祖本纪》
获取渠道：维基文库
URL：https://zh.wikisource.org/wiki/史記/卷008
获取日期：2024-12-01
版权状态：公共领域（Public Domain）

---

# 高祖本纪

[段落内容]
```

**数据来源**：
- 📖 [维基文库](https://zh.wikisource.org) - 免费古籍文本
- 📖 [中国哲学书电子化计划](https://ctext.org) - 高质量古籍资源

#### 1.2 预处理（生成结构化 JSON）

使用预处理脚本将原始文本转换为结构化 JSON：

```bash
node scripts/preprocess_text.js \
  --input "data/raw/shiji/shiji_01_gaozu_benji.txt" \
  --output "data/processed/chapters/shiji_01_gaozu_benji.json" \
  --book "史记" \
  --chapter "高祖本纪" \
  --url "https://zh.wikisource.org/wiki/史記/卷008"
```

**参数说明**：
- `--input`: 输入文本文件路径（必需）
- `--output`: 输出 JSON 文件路径（必需）
- `--book`: 书籍名称（可选）
- `--chapter`: 章节名称（可选）
- `--url`: 来源 URL（可选）

**脚本功能**：
- ✅ 提取章节标题
- ✅ 按段落分割文本
- ✅ 为每个段落添加编号和 ID
- ✅ 生成标准 JSON 格式

**输出格式**：
```json
{
  "title": "高祖本纪",
  "source": {
    "book": "史记",
    "chapter": "高祖本纪",
    "url": "https://zh.wikisource.org/wiki/史記/卷008"
  },
  "paragraphs": [
    {
      "order": 1,
      "text": "段落内容...",
      "id": "para_1"
    }
  ]
}
```

**预期输出**：
```
✅ 处理完成：XX 个段落
   输出文件：data/processed/chapters/shiji_01_gaozu_benji.json
```

---

### 步骤 2：上传章节

#### 2.1 创建书籍（如果还没有）

1. 登录管理后台：http://localhost:5173/admin/login
2. 进入 **内容管理 → 书籍管理**
3. 点击 **新建书籍**
4. 填写书籍信息：
   - 书名：如"史记"
   - 英文名：如"shiji"
   - 作者：如"司马迁"
   - 朝代：如"西汉"
   - 其他信息（可选）
5. 点击 **保存**

#### 2.2 上传章节 JSON

1. 进入 **内容管理 → 书籍章节**
2. 选择 **导入章节** 标签页
3. 选择书籍（从下拉框选择）
4. 选择章节 JSON 文件
5. 点击 **开始导入**

**注意**：
- 章节会保存到数据库
- 段落会自动创建
- 此时还没有提取数据

---

### 步骤 3：提取数据

#### 3.1 进入章节处理页面

1. 进入 **内容管理 → 章节处理**
2. 选择书籍（从下拉框选择）
3. 选择章节（从下拉框选择）

#### 3.2 提取模式（混合，事件为中心）

- 系统默认使用"事件联合抽取 + 人物/地点补全 + 对齐消歧"，无需勾选类型。
- 每批事件上限 30，人物/地点上限 60；超出会按重要性截断并在结果中标记长尾。
- 文本分段：约 4k-6k tokens（长章 8k-12k），防止超长输入稀释注意力。
- 默认模型：Gemini `gemini-2.5-flash`，温度 0.3。

#### 3.3 开始提取

1. 点击 **开始提取** 按钮
2. 等待提取完成（显示 loading 状态）
3. 查看提取结果：
   - 人物：X 条
   - 关系：X 条
   - 地点：X 条
   - 事件：X 条

**注意**：
- 提取是同步的，可能需要几分钟（取决于章节大小）
- 提取结果会自动创建 ReviewItem，状态为 `PENDING`
- 如果提取失败，会显示错误信息，可以重试；失败的分段/长尾会保留标记，便于后续补抽

---

### 步骤 4：批量审核

#### 4.1 在章节处理页面审核

1. 在章节处理页面下方查看 **待审核数据** 列表
2. 勾选要审核的数据（可以全选）
3. 点击 **批量通过** 或 **批量拒绝**

**批量通过**：
- 系统会自动判断是否重复
- 如果检测到重复，会使用 LLM 融合
- 通过后数据状态直接设为 `PUBLISHED`（已发布）

**批量拒绝**：
- 标记为 `REJECTED`
- 可以填写拒绝原因

#### 4.2 在 Review 页面审核（可选）

1. 进入 **数据准备 → Review**
2. 筛选待审核数据（状态：待审核）
3. 勾选要审核的数据
4. 点击 **批量通过** 或 **批量拒绝**

**优势**：
- 可以按类型筛选（人物、关系、地点、事件）
- 可以查看详细信息
- 支持单个审核

---

### 步骤 5：完成 ✅

审核通过后：
- ✅ 数据状态为 `PUBLISHED`
- ✅ 可以直接在系统中使用
- ✅ 可以在人物、关系、地点、事件页面查看

---

## 📚 推荐章节

### 史记

- 高祖本纪：https://zh.wikisource.org/wiki/史記/卷008
- 项羽本纪：https://zh.wikisource.org/wiki/史記/卷007
- 秦始皇本纪：https://zh.wikisource.org/wiki/史記/卷006
- 萧相国世家：https://zh.wikisource.org/wiki/史記/卷053
- 留侯世家：https://zh.wikisource.org/wiki/史記/卷055
- 淮阴侯列传：https://zh.wikisource.org/wiki/史記/卷092

### 汉书

- 高帝纪：https://zh.wikisource.org/wiki/漢書/卷001上
- 惠帝纪：https://zh.wikisource.org/wiki/漢書/卷002
- 文帝纪：https://zh.wikisource.org/wiki/漢書/卷004
- 萧何传：https://zh.wikisource.org/wiki/漢書/卷039

---

## ❓ 常见问题

### Q1: 如何快速获取章节数据？

**推荐方法**：
使用自动脚本一键完成下载和预处理：

```bash
# 下载《史记·高祖本纪》并预处理
./scripts/download_first_chapter_auto.sh
```

**手动方法**：
1. 使用下载脚本：`node scripts/download_with_playwright.js --url "..." --output "..."`
2. 使用预处理脚本：`node scripts/preprocess_text.js --input "..." --output "..."`

### Q2: 下载脚本失败怎么办？

A: 
1. 检查网络连接
2. 确认 URL 是否正确
3. 尝试手动下载
4. 检查 Playwright 是否正确安装：`npx playwright install chromium`

### Q3: 预处理脚本报错？

A:
1. 检查文件编码（必须是 UTF-8）
2. 检查文件格式（段落用空行分隔）
3. 检查文件路径是否正确

### Q4: 提取失败怎么办？

**可能原因**：
- LLM API 配置错误
- 网络问题
- 章节文本过长

**解决方法**：
1. 检查环境变量（`OPENAI_API_KEY` 或 `GOOGLE_API_KEY`）
2. 检查网络连接
3. 重试提取
4. 如果章节过长，系统会自动分段处理

### Q5: 提取时间太长怎么办？

**说明**：
- 大章节提取可能需要 5-10 分钟
- 这是正常的，因为需要调用 LLM API
- 前端会显示 loading 状态

**建议**：
- 耐心等待
- 不要关闭页面
- 如果超时，可以重试

### Q6: 如何清理旧的提取数据？

**操作**：
- 运行清理脚本（需要 ts-node）：  
  ```bash
  npx ts-node backend/scripts/cleanup_old_extraction.ts
  ```
- 将删除 `source` 为 `LLM_EXTRACT` 的 ReviewItem；已发布数据不受影响。

### Q7: 审核通过后数据在哪里？

**答案**：
- 人物数据：**内容管理 → 人物管理**
- 关系数据：**内容管理 → 关系管理**
- 地点数据：**内容管理 → 地点管理**
- 事件数据：**内容管理 → 事件管理**

所有数据状态为 `PUBLISHED`，可以直接使用。

### Q8: 如何修改已发布的数据？

**方法**：
1. 进入对应的管理页面（如人物管理）
2. 找到要修改的数据
3. 点击编辑按钮
4. 修改后保存

**注意**：修改会记录到变更日志中。

### Q9: 批量审核时如何知道哪些数据会合并？

**说明**：
- 系统会自动检测重复
- 如果检测到重复，会在 ReviewItem 中标记
- 批量通过时会自动使用 LLM 融合
- 融合结果会记录到变更日志中

**建议**：
- 批量通过前可以先查看单个 ReviewItem 的详情
- 确认融合结果后再批量操作

### Q10: LLM 提取的数据不准确？

A:
1. 检查原始文本质量
2. 优化提示词（修改后端代码中的 prompt）
3. 使用更高质量的模型（如 `gemini-1.5-pro`）
4. 人工 Review 修正

### Q11: 如何提高提取准确率？

A:
1. **分段提取**：系统会自动分段，长章会分成多段处理
2. **交叉验证**：对比不同书籍的数据，确保准确性
3. **人工审核**：所有数据都需要人工 Review

### Q12: API Key 设置问题？

A:
1. 确认 `.env` 文件在项目根目录
2. 确认环境变量名称正确（`GOOGLE_API_KEY` 或 `OPENAI_API_KEY`）
3. 确认 API Key 有效（未过期、有额度）

---

## 💡 最佳实践

### 1. 工作流程建议

**推荐流程**：
1. 一次上传一个章节
2. 提取后立即审核
3. 审核通过后再处理下一个章节

**优势**：
- 避免数据堆积
- 及时发现和解决问题
- 保持数据质量

### 2. 数据准备

**小批量处理**：
- 每次处理 1-2 个章节，不要一次性处理太多
- 确保每个章节的数据质量

**文件管理**：
- 保持文件命名规范：`{book}_{chapter}_{title}.txt`
- 及时备份原始文本和预处理后的 JSON

### 3. 提取模式选择

- 默认使用"事件联合 + 人物/地点补全 + 对齐消歧"混合模式，无需手动勾选类型。
- 每批事件≤30，人物/地点≤60；截断的长尾会被标记，后续可单独补抽。
- 如果章节极短，可接受一次性输出；长章建议保持分段，便于并行与重试。

### 4. 批量审核策略

**小批量审核**（推荐）：
- 每次审核 10-20 条数据
- 可以仔细检查每条数据
- 减少错误率

**大批量审核**：
- 适合数据质量较高的情况
- 可以快速处理大量数据
- 但需要仔细检查融合结果

### 5. 数据质量检查

**审核时注意**：
- ✅ 人物姓名是否正确
- ✅ 关系类型是否准确
- ✅ 地点坐标是否合理
- ✅ 事件时间是否准确
- ✅ 融合结果是否合理

### 6. 错误处理

**如果发现错误**：
1. 拒绝错误的 ReviewItem
2. 在对应的管理页面修改已发布的数据
3. 或者删除错误数据后重新提取

### 7. 持续改进

- **记录问题**：记录提取和审核中发现的问题，持续改进
- **版本控制**：对提取的数据进行版本管理，便于回溯
- **交叉验证**：对比不同书籍的数据，确保准确性

---

## 📊 数据统计

### 查看提取结果

在章节处理页面可以看到：
- 人物数量
- 关系数量
- 地点数量
- 事件数量

### 查看审核状态

在 Review 页面可以：
- 查看待审核数量
- 查看已通过数量
- 查看已拒绝数量

---

## 🔗 相关文档

- [数据获取与融合规格书](../specs/data-acquisition-and-merge-spec.md) - 详细技术规范
- [渐进式工作流指南](../scripts/INCREMENTAL_WORKFLOW.md) - 适合第一次使用
- [快速开始指南](./setup/QUICK_START.md) - 环境设置
- [数据来源说明](./data/DATA_SOURCES.md) - 数据来源和版权
- [推荐书籍](./data/RECOMMENDED_BOOKS.md) - 推荐的历史书籍
- [Google Gemini API 设置](../scripts/GEMINI_SETUP.md) - API Key 配置

---

## 📝 更新日志

### v2.1 (2024-12-08)

- ✅ 整合数据准备完整指南
- ✅ 添加前置要求章节
- ✅ 扩展数据准备步骤说明
- ✅ 添加推荐章节列表
- ✅ 完善常见问题和最佳实践

### v2.0 (2024-12-08)

- ✅ 新增章节处理页面，统一管理章节相关操作
- ✅ 支持在系统中直接提取数据，无需线下脚本
- ✅ 简化审核流程，审核通过即发布
- ✅ 支持批量审核，提高操作效率

---

**最后更新**：2024-12-08  
**版本**：2.1
